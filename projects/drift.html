<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DRIFT - RL for Floating Platforms | Matteo El Hariry</title>
    <link rel="stylesheet" href="../assets/css/custom.css">
</head>

<body>
    <!-- Navigation Bar -->
    <nav class="navbar">
        <div class="navbar-brand">
            <a href="../index.html">Matteo El Hariry</a>
        </div>
        <div class="navbar-links">
            <a href="../index.html#about">About</a>
            <a href="../index.html#projects">Projects</a>
            <a href="../index.html#publications">Publications</a>
            <a href="../index.html#contact">Contact</a>
        </div>
        <button class="theme-toggle" onclick="toggleTheme()">
            üåô Dark
        </button>
    </nav>

    <!-- Project Header -->
    <section class="project-header">
        <h1>DRIFT</h1>
        <h2>Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories</h2>
        <div class="project-meta">
            <span class="project-type">Autonomous Space Robotics</span>
            <span class="project-role">PhD Research Project</span>
        </div>
    </section>

    <!-- Project Overview -->
    <section class="project-section">
        <h2>Project Overview</h2>
        <div class="project-banner-image">
            <div class="project-video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/DgYw743_6VI" frameborder="0" allowfullscreen></iframe>
            </div>
            <div class="project-description">
                <p>
This investigation introduces a novel deep reinforcement learning-based suite to control floating platforms in both simulated and real-world environments. Floating platforms serve as versatile test-beds to emulate microgravity environments on Earth, useful to test autonomous navigation systems for space applications. Our approach addresses the system and environmental uncertainties in controlling such platforms by training policies capable of precise maneuvers amid dynamic and unpredictable conditions. Leveraging Deep Reinforcement Learning (DRL) techniques, our suite achieves robustness, adaptability, and good transferability from simulation to reality. Our deep reinforcement learning framework provides advantages such as fast training times, large-scale testing capabilities, rich visualization options, and ROS bindings for integration with real-world robotic systems. Being open access, our suite serves as a comprehensive platform for practitioners who want to replicate similar research in their own simulated environments and labs.
                </p>
            </div>
        </div>
    </section>

    <!-- Framework Overview -->
    <section class="project-section">
        <h2>Framework Overview</h2>
        <div class="framework-content">
            <div class="project-images">
                <img src="../assets/img/drift/drift_framework.png" alt="DRIFT Framework Overview" class="project-banner-image">
            </div>
            <div class="framework-description">
                <p>
                    Framework Employed for Training and Evaluation: On the left, we depict the agent‚Äôs interaction during both training
                    and evaluation phases with the simulation environments, highlighting the incorporation of disturbances in the loop. On the
                    right, we illustrate the deployment of the trained policy, while performing open-loop control on the real FP system.
                </p>
            </div>
        </div>
    </section>

    <!-- Key Results -->
    <section class="project-section">
        <h2>Key Results</h2>
        <div class="results-subsection">
            <h3>Simulation Performance</h3>
                <div class="result-item">
                </div>
                    <p>
                        Simulation performed using Omniverse Isaac Sim, showcasing the platform's ability to quickly (a model is trained in parallel across multiple environments) and converges in less than 10 minutes.
                    </p>
                <div class="result-item">
                    <div class="result-media">
                        <img src="../assets/gifs/drift/fp_sim_multi.gif" alt="DRIFT Simulation Performance" class="result-gif">
                        <img src="../assets/gifs/drift/docking_lab.gif" alt="DRIFT Simulation Performance" class="result-gif">
                    </div>

                    <div class="result-media">
                        <img src="../assets/gifs/drift/fp_sim_multi_2.gif" alt="DRIFT Simulation Performance" class="result-gif">
                        <img src="../assets/gifs/drift/docking_sim.gif" alt="DRIFT Simulation Performance" class="result-gif">
                        <img src="../assets/gifs/drift/go_to_position_3d_sim.gif" alt="DRIFT Simulation Performance" class="result-gif">
                    </div>
                </div>
                </div>
        </div>
        
        <!-- Real Lab Results -->
        <div class="results-subsection">
            <h3>Real Laboratory Validation</h3>
            <div class="results-content">
                <div class="result-description">
                    <p>
                        Direct transfer of simulation-trained policies to the physical floating platform demonstrates 
                        successful sim-to-real capabilities. The system maintains stable control despite real-world 
                        uncertainties including air currents, sensor noise, and mechanical variations.
                    </p>
                </div>
                <div class="result-item">
                    <div class="result-media">
                        <img src="../assets/gifs/drift/fp_lab_infinite_traj.gif" alt="DRIFT Simulation Performance" class="result-gif">
                        <img src="../assets/gifs/drift/fp_lab_square_traj.gif" alt="DRIFT Simulation Performance" class="result-gif">
                    </div>
                    <div class="result-media">
                        <img src="../assets/gifs/drift/fp_lab_spyral_traj.gif" alt="DRIFT Simulation Performance" class="result-gif">
                        <img src="../assets/gifs/drift/fp_lab_circle_traj.gif" alt="DRIFT Simulation Performance" class="result-gif">
                    </div>
                </div>
                
                <div class="result-item">
                    <div class="result-media">
                        <img src="../assets/img/drift/drift_track_vel_result.png" alt="DRIFT Real Experiments" class="result-gif">
                    </div>
                </div>
            </div>
        </div>

        <!-- Performance Summary -->
        <div class="performance-summary">
            <h3>Performance Highlights</h3>
            <div class="performance-grid">
                <div class="performance-metric">
                    <div class="metric-value">¬±2.5cm</div>
                    <div class="metric-label">Position Accuracy</div>
                </div>
                <div class="performance-metric">
                    <div class="metric-value">¬±1.2¬∞</div>
                    <div class="metric-label">Orientation Precision</div>
                </div>
                <div class="performance-metric">
                    <div class="metric-value">5Hz</div>
                    <div class="metric-label">Control Frequency</div>
                </div>
                <div class="performance-metric">
                    <div class="metric-value">95%</div>
                    <div class="metric-label">Success Rate</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Publications -->
    <section class="project-section">
        <h2>Related Publications</h2>
        <div class="publication-list">
            <div class="publication-item">
                <h3><a href="https://arxiv.org/abs/2310.04266">DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories</a></h3>
                <p><strong>Matteo El-Hariry</strong>, Antoine Richard, Vivek Muralidharan, Matthieu Geist, Miguel Olivares-Mendez</p>
                <p><em>IROS '24 (oral presentation) & MASSpace'24 (International Workshop on Autonomous Agents and Multi-Agent Systems for Space Applications)</em></p>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2310.04266" target="_blank">ArXiv Paper</a>
                    <a href="https://www.youtube.com/watch?v=DgYw743_6VI&embeds_referring_euri=http%3A%2F%2F0.0.0.0%3A8000%2F" target="_blank">Video Presentation</a>
                    <a href="https://github.com/elharirymatteo/RANS" target="_blank">Code Repository</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Navigation -->
    <section class="project-navigation">
        <a href="react.html" class="nav-button">‚Üê Previous: REACT</a>
        <a href="../index.html" class="nav-button">Back to Portfolio</a>
        <a href="ice2thrust-project.html" class="nav-button">Next Project: ICE2THRUST ‚Üí</a>
    </section>

    <script>
        function toggleTheme() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
            
            const button = document.querySelector('.theme-toggle');
            button.textContent = newTheme === 'dark' ? '‚òÄÔ∏è Light' : 'üåô Dark';
        }

        document.addEventListener('DOMContentLoaded', function() {
            const savedTheme = localStorage.getItem('theme') || 'light';
            document.documentElement.setAttribute('data-theme', savedTheme);
            
            const button = document.querySelector('.theme-toggle');
            button.textContent = savedTheme === 'dark' ? '‚òÄÔ∏è Light' : 'üåô Dark';
        });
    </script>
</body>

</html>
